{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5d999fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast, GPT2Config\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "15da417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 30000\n",
    "MAX_LEN = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d39b6fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZER_SAVEDIR = Path('/home/macosta/ttmp/primus-data/primus-agnostic/agnostic-tokenizer-split/')\n",
    "LM_MODEL_SAVEDIR = Path('/home/macosta/ttmp/primus-models/gpt2-lm-agnostic-split/')\n",
    "PRIMUS_TXT_FILES = Path('/home/macosta/ttmp/primus-data/primus-agnostic/agnostic/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d52484a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = GPT2Config(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    n_positions=MAX_LEN,\n",
    "    n_head=12,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b0e85caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel(config=config).from_pretrained(str(LM_MODEL_SAVEDIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "be9c9806",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "file /home/macosta/ttmp/primus-data/primus-agnostic/agnostic-tokenizer-split/config.json not found\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2TokenizerFast.from_pretrained(TOKENIZER_SAVEDIR, max_len=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6cad7376",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(PRIMUS_TXT_FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f537947d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"<pad>\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "387bdfd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> clef.C L1 accidental.flat L4 accidental.flat L2 accidental.flat S3 metersign.C L3 digit.1 S5 multirest L3 barline L1 rest.half L3 rest.quarter L3 rest.eighth L3 note.eighth L4 barline L1 note.quarter S5 dot S5 note.eighth L4 note.quarter L4 dot S4 note.eighth S5 barline L1 note.quarter L5 note.quarter L5 rest.quarter L3 rest.eighth L3 note.eighth L4 barline L1 note.quarter L6 dot S6 note.eighth S3 note.quarter S3 dot S3 note.eighth S4 barline L1 note.quarter S4 note.quarter L4 rest.quarter L3 </s>\n"
     ]
    }
   ],
   "source": [
    "input_str = tokenizer.encode(\"<s> clef.C\", return_tensors=\"pt\")\n",
    "output_tokens = model.generate(input_str, \n",
    "                               pad_token_id=1,\n",
    "                               eos_token_id=2,\n",
    "                               temperature=1,\n",
    "                               max_length=128)[0]\n",
    "output_tokens = tokenizer.decode(output_tokens).split()\n",
    "print(' '.join(output_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dd384350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def continue_image(file, seed_length=100, pred_length=500, max_len=128, show=True, show_original=True, temp=1):\n",
    "    with open(file, 'r') as f:\n",
    "        data = f.read()\n",
    "    tokens = data.split()\n",
    "    index = int(np.random.random()*(len(tokens) - seed_length))\n",
    "    seed = tokens[index:index + seed_length]\n",
    "    if show_original:\n",
    "        tokens_to_image(seed).show()\n",
    "    input_string = f\"{' '.join(seed[-(max_len - 1):])}\"\n",
    "    inputs = tokenizer.encode(input_string, return_tensors=\"pt\")\n",
    "    output_tokens = model.generate(inputs, \n",
    "                                   min_length=seed_length, \n",
    "                                   max_length=max_len, \n",
    "                                   pad_token_id=50256,\n",
    "                                   temperature=temp,\n",
    "                                   num_beams=5)[0]\n",
    "    output_tokens = tokenizer.decode(output_tokens).split()\n",
    "    img = tokens_to_image(output_tokens)\n",
    "    img.show()\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "77e6d424",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAABfCAAAAACPPsvpAAAApUlEQVR4nO2VURKAIAhEoen+V7a/RAPExpqdYr8qeYE7bnGhWW3TRCKgCKyYaPZgwpr8DrIP1pmIOlNdk7leiiJnMGZ5E0AaoGEshO0nBnIlAoPNIl4THXEJXGkHRt/KWRY2ub74wbyI6Ud5uQDBLq1BBiKLSmepNVjRIuwjTr5hv2OwCKyMVHr/T1iTE0nkG8pUJvJbBFas5C9TuRjRTF7f5QZyAMNnGJtwb9DmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=50x95 at 0x7F43BC57CA50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAABfCAAAAAAFPZDtAAAA80lEQVR4nO2ZSw7DMAgFoer9r+wuG9XgoLhApMxb5SP5jbDBxNEhvXo1+wMAAAAAoH6pSO921L4IAQDgffJeRSQ1UZZpqN/LNITFFKgeb8oB9Mcyi8ADmP2SCByAtIhHAepkA9QFwAYo9Ef9skqxvQSuFONppHmQcBr+xd94klkHQskUBUjbDc/6gQ37WDUJRSDR3wM4Wo7UDwdvCkZ+M7YG2LaOFpObbsdZMqL6rAhYyypWiNLsKyPQfSqOPDkd0f6ERQd5Vh0AAAAAAAAAAHRL0REBAAAAAAAAQDsAapcabQsdEQAAlMr6X1B6sN4egXaAD6iOIaH+z21fAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=128x95 at 0x7F43BC48DAD0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = continue_image(PRIMUS_TXT_FILES / str(files[1]), seed_length=50, temp=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
