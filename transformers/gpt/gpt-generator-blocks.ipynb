{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d999fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast, GPT2Config\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15da417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 30000\n",
    "MAX_LEN = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d39b6fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZER_SAVEDIR = Path('/home/macosta/ttmp/primus-data/blocks/blocks-v2-tokenizer/')\n",
    "LM_MODEL_SAVEDIR = Path('/home/macosta/ttmp/primus-models/gpt2-lm-blocks/')\n",
    "TXT_FILES = Path('/home/macosta/ttmp/primus-data/blocks/blocks-txt-v2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ee50c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "TXT_FILEPATHS = [TXT_FILES / f for f in os.listdir(TXT_FILES)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d52484a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = GPT2Config(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    n_positions=MAX_LEN,\n",
    "    n_head=12,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0e85caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel(config=config).from_pretrained(str(LM_MODEL_SAVEDIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be9c9806",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "file /home/macosta/ttmp/primus-data/blocks/blocks-v2-tokenizer/config.json not found\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2TokenizerFast.from_pretrained(TOKENIZER_SAVEDIR, max_len=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a34ea24d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('<col>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f883d66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMPTY = np.ones((15, 15), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "678d210f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e1c0dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blocks_to_img(tokens):\n",
    "    tokens = [t for t in tokens if t not in ['<s>', '</s>']]\n",
    "    columns = ' '.join(tokens).split('<col>')\n",
    "    columns = [c.strip().split() for c in columns if c]\n",
    "    columns = [[np.array([int(x) for x in b]).reshape((15, 15)) if b != '<unk>' else EMPTY for b in tokens] for tokens in columns]\n",
    "    img_arr = np.ones((6 * 15 + 3 * 5, len(columns) * 15), dtype=np.uint8)\n",
    "    for i, column in enumerate(columns):\n",
    "        for j in range(min(6, len(column))):\n",
    "            img_arr[j*18:j*18+15, i*15:i*15+15] = column[j]\n",
    "    for i in range(15, 15 + 5 * 18 + 1, 18):\n",
    "        img_arr[i:i+3,:] = 0\n",
    "    return Image.fromarray(img_arr * 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c3308ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(show=False):\n",
    "    random_file = TXT_FILEPATHS[int(len(TXT_FILEPATHS) * random.random())]\n",
    "    with open(random_file, 'r') as f:\n",
    "        file_contents = f.read()\n",
    "    columns = file_contents.split('<col>')\n",
    "    columns = [c for c in columns if c]\n",
    "    random_column = columns[int(len(columns) * random.random())]\n",
    "    input_str = tokenizer.encode(f'{random_column} <col>', return_tensors='pt')\n",
    "#     input_str = torch.tensor([[5]])\n",
    "    output_tokens = model.generate(input_str, \n",
    "                                   pad_token_id=1,\n",
    "                                   eos_token_id=2,\n",
    "                                   temperature=1,\n",
    "                                   min_length=MAX_LEN,\n",
    "                                   max_length=MAX_LEN,\n",
    "                                   do_sample=True,\n",
    "                                   bad_words_ids=[[3]])[0]\n",
    "    assert len(output_tokens) == MAX_LEN\n",
    "    output_tokens = tokenizer.decode(output_tokens).split()\n",
    "    img = blocks_to_img(output_tokens)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "246c5810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_until_end_token(max_extend=512):\n",
    "#     random_file = TXT_FILEPATHS[int(len(TXT_FILEPATHS) * random.random())]\n",
    "#     with open(random_file, 'r') as f:\n",
    "#         file_contents = f.read()\n",
    "#     columns = file_contents.split('<col>')\n",
    "#     columns = [c for c in columns if c]\n",
    "#     random_column = columns[int(len(columns) * random.random())]\n",
    "#     input_tensors = tokenizer.encode(f'{random_column} <col>', return_tensors='pt')\n",
    "    input_tensors = torch.tensor([tokenizer.encode('<s>')])\n",
    "    output_tokens = model.generate(input_tensors, \n",
    "                                   pad_token_id=1,\n",
    "                                   eos_token_id=2,\n",
    "                                   temperature=1,\n",
    "                                   min_length=MAX_LEN,\n",
    "                                   max_length=MAX_LEN,\n",
    "                                   do_sample=True)\n",
    "    assert len(output_tokens[0]) == MAX_LEN\n",
    "    full_sequence = list(output_tokens[0])\n",
    "    input_tensors = output_tokens[:, 1:]\n",
    "    for i in tqdm(range(max_extend)):\n",
    "        output_tokens = model.generate(input_tensors, \n",
    "                                   pad_token_id=1,\n",
    "                                   eos_token_id=2,\n",
    "                                   temperature=1,\n",
    "                                   min_length=MAX_LEN,\n",
    "                                   max_length=MAX_LEN,\n",
    "                                   do_sample=True)\n",
    "        assert len(output_tokens[0]) == MAX_LEN\n",
    "        last_token = output_tokens[0, -1]\n",
    "        full_sequence.append(last_token)\n",
    "        if tokenizer.decode(last_token) == '</s>':\n",
    "            break\n",
    "        input_tensors = output_tokens[:, 1:]\n",
    "    full_sequence_decoded = tokenizer.decode(full_sequence).split()\n",
    "    output = [t for t in full_sequence_decoded if t not in ['<s>', '</s>']]\n",
    "    img = blocks_to_img(output)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9a866f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 256/256 [00:22<00:00, 11.41it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=825x105 at 0x7FB6E4157810>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate_until_end_token(max_extend=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fcc06081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAR0AAABpCAAAAAAixajEAAACmUlEQVR4nO2c25aDIAxFwyz//5czD2J1KRyIpbUJZ7/MpS6FbQgQnUkqpMrf0w34aVY7KT3cjB9lERGqqcGRhaAdBO0gaAdBOwjaQdAOgnYQtIOgHQTtEEK+TdK1gvGdEmH61oUGwayMoB0E7SBoB7GsX1RyedlV0vw4OXYSa+8lcuwU3HibfT8B8w7iYEf1HCvTD7aXHVW5DqXZ9fzJ6mT6FFOkkXcmD55WVp5bT3POmlsPIeQDpLz/VJHT5uGYcEbN90/uTu5UQPt2ErOm5qMd4CCIHms3lv3ba+jpfrp0DcqUjwnMK3ZScVzuO9OL9nT+fcAXVzc79cLgJujU94KteGF0zDvV3sXptjG8dzuX6s4BfdWdR13XB3t9Bx/X+Dh5qbPabuJmp9k1rZxZJWQ+Xlln9Bu3XbcJPaoZkRw7XXLOwbPmqZREVFWdDCzj0Frah2zo+cQHH0EDaL4nNpYbOcyOk4ElYeOcED8UKhPbJ4VHo5WDuxfKt1fUI7a4aV+c9Z5ssjkra+lNzIPsuJmxbA212KkZdzVFFotVNSYbWWKLnjF23Awskf3hVAcmO2UJrgaWDYOdMBb6g2fIyHI1sMTQ3vfteA2pnnZb7HgLkTrj18p113GsnTHETqQZq/0ESkQMdnxaeJP+2In1pNRlowkJQmdtsH6Y7WpP1waNbeF7g4jOOStmim/e9D47MeW0ma82aIF2ELSDoB0E7SBoB0E7iKntDNpJzArtIKa1M+vGmpAfwPTe4HPcqw2Cl/P7uhc5K7+feA1/J+ENLKcrFuPGzogpO6ydIeuZsHaGENVOKXTs015UO2OgHURQO2MGVlQ7Be4stoPauaq4tSsKaufCvS1jVDsKf+zFjR3r2vfoA/0DFMg/4upzrWUeptgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=285x105 at 0x7FB6E421C790>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate_image(show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3a67a743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(n, savepath):\n",
    "    savepath.mkdir(exist_ok=True)\n",
    "    for i in tqdm(range(n)):\n",
    "        img = generate_image()\n",
    "        img.save(savepath / f\"generated-blockwise-{i}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b558edbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_long_images(n, savepath):\n",
    "    savepath.mkdir(exist_ok=True)\n",
    "    for i in range(n):\n",
    "        img = generate_until_end_token(max_extend=512)\n",
    "        img.save(savepath / f\"generated-blockwise-{i}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "923d7793",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████                                                                            | 70/512 [00:06<00:38, 11.35it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3647828/780118753.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate_long_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msavepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/macosta/ttmp/generated-blockwise-long/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_3647828/3818265461.py\u001b[0m in \u001b[0;36mgenerate_long_images\u001b[0;34m(n, savepath)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msavepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_until_end_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_extend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msavepath\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34mf\"generated-blockwise-{i}.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3647828/4073501705.py\u001b[0m in \u001b[0;36mgenerate_until_end_token\u001b[0;34m(max_extend)\u001b[0m\n\u001b[1;32m     25\u001b[0m                                    \u001b[0mmin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_LEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                                    \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_LEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                                    do_sample=True)\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mMAX_LEN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mlast_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mir2/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mir2/lib/python3.7/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, stopping_criteria, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1208\u001b[0m                 \u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m                 \u001b[0msynced_gpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynced_gpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1210\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1211\u001b[0m             )\n\u001b[1;32m   1212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mir2/lib/python3.7/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1712\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1713\u001b[0m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1714\u001b[0;31m                 \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1715\u001b[0m             )\n\u001b[1;32m   1716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mir2/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mir2/lib/python3.7/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m         )\n\u001b[1;32m   1062\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mir2/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mir2/lib/python3.7/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    896\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                     \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m                 )\n\u001b[1;32m    900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mir2/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mir2/lib/python3.7/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0mfeed_forward_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m         \u001b[0;31m# residual connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfeed_forward_hidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mir2/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mir2/lib/python3.7/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mir2/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mir2/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1835\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1836\u001b[0m         \u001b[0msize_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1837\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1838\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msize_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1839\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "generate_long_images(30, savepath=Path('/home/macosta/ttmp/generated-blockwise-long/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "98076340",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [02:38<00:00,  5.29s/it]\n"
     ]
    }
   ],
   "source": [
    "# generate_images(30, savepath=Path('/home/macosta/ttmp/generated-blockwise/'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
