{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d999fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast, GPT2Config\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15da417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 30000\n",
    "MAX_LEN = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9e7e362",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZER_SAVEDIR = Path('/home/macosta/ttmp/primus-leipzig-delim-tokenizer')\n",
    "LM_MODEL_SAVEDIR = Path('/home/macosta/ttmp/gpt2-lm-model-delim/')\n",
    "PRIMUS_TXT_FILES = Path('/home/macosta/ttmp/primus-leipzig-delim-txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d52484a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = GPT2Config(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    n_positions=MAX_LEN,\n",
    "    n_head=12,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0e85caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel(config=config).from_pretrained(str(LM_MODEL_SAVEDIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be9c9806",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "file /home/macosta/ttmp/primus-leipzig-delim-tokenizer/config.json not found\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2TokenizerFast.from_pretrained(TOKENIZER_SAVEDIR, max_len=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f99b0c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "STAFFLINE_A = \"0000000000000000000000000000000000000000000000000011100000000000000011100000000000000011100000000000000011100000000000000011100000000000000000000000000000000000000000000000000\"\n",
    "STAFFLINES = \"_\" + f\"{STAFFLINE_A}_\" * 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6d9301a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_image(tokens):\n",
    "    tokens = [t for t in tokens if t[0] != '<']\n",
    "    tokens = STAFFLINES.join(tokens)\n",
    "    tokens = tokens.split('_')\n",
    "    tokens = [t for t in tokens if t and t[0] != '<']\n",
    "    img_array = np.zeros((len(tokens[0]), len(tokens)), dtype=np.uint8)\n",
    "    for j, column in enumerate(tokens):\n",
    "        for i, char in enumerate(column):\n",
    "            img_array[i, j] = (1-int(char)) * 255\n",
    "    img = Image.fromarray(img_array)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd384350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def continue_image(file, seed_length=100, pred_length=500, max_len=128, show=True, show_original=True, temp=1):\n",
    "    with open(file, 'r') as f:\n",
    "        data = f.read()\n",
    "    tokens = data.split()\n",
    "    index = int(np.random.random()*(len(tokens) - seed_length))\n",
    "    seed = tokens[index:index + seed_length]\n",
    "    if show_original:\n",
    "        tokens_to_image(seed).show()\n",
    "    input_string = f\"{' '.join(seed[-(max_len - 1):])}\"\n",
    "    inputs = tokenizer.encode(input_string, return_tensors=\"pt\")\n",
    "    output_tokens = model.generate(inputs, \n",
    "                                   min_length=seed_length, \n",
    "                                   max_length=max_len, \n",
    "                                   pad_token_id=1,\n",
    "                                   temperature=temp,\n",
    "                                   num_beams=5,\n",
    "                                   eos_token_id=2)[0]\n",
    "    output_tokens = tokenizer.decode(output_tokens).split()\n",
    "    img = tokens_to_image(output_tokens)\n",
    "    img.show()\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13ac3853",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(PRIMUS_TXT_FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "77e6d424",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUcAAACvCAAAAABLQkPsAAAESElEQVR4nO2c25aDIAxFwyz//5eZh7aC2gqBwy2e/TDTdpwqe0US48V5IQD+Rm+AEegRAz1ioEcM9IiBHjHQIwZ6xECPGOgRAz1ioEcM9IiBHjFsozcgjRMRkcn7ewt4fOH2V1MaXcZjIBidSOmCHiPmCdK1PQZGG7XiMbAb7SrUnsedriFq2GOgQ2Z6hMeIVkG6hEcfRxQKrNElPMZDndRo5NENL8JymNToJiLiVhB4IdpovFKt0UX26wT7WIfFqA2PO36fnBoYvcOYx0DTefSKWY+BLkYf4DHQMDM9ymOEF3lXehijT/UYwOz29BioMUqP39DXowePbnx/fjKyM9OWtRRJsYmIo8VqNjqE8EeNEHh9D4Zj3cNsXcohHqmxmHc8emHpU8UrHhmItWyMRAjM1xjokRBCvuP850fGdSnXvN6jYFJdLzNkYafrhzuRjzm3f8TSU0RO+dq5u0oy/lvns+zzEzymhLjDL4bhkbfH+0g8cBbJgBQR2URclgvqumXT+ym9WtKJ4emg0/nrkN+NqjwdX/8epM9Y5heHydfmBHGIxzahcha35lXUCfZ49KnR+dPv8+e/uMafxYh8xWNWhPjoeCZfhkVpX9D0w2PbY+6GnJeyfJ1/V8RDwlHv8SAmGYxP0UgIMYiqHx7/3+fF7f98nR6bdt1H9cNLz7u2a5utmZqifJ2VfK8LaQ/zEouvqVERj69mw95yKK2/jdbtfyLKsV0CRhNByaP4RcMxPx4vAywJLLt1e8f7kJru0aOb7QCP95vvxaUXqlnBHM32DvFYUpUqcD/f9KTcY7dN1lf6A9DX4dp+eFNm0Zjv8ayrto7M5m4F02hUxONhPNXleMY6WqygGYr58XV+RtnIreT+++cJR9X8eBlU8uhEjb99e2IijYQQg+gvEtE8JLXpkZq+2d6q017RD1+RlnlJ7XHKp8nvDCvaK+JxtMapinZLz0EaWW2Wx+PocJyraC+Ox/f9SENt+h6PrM/rtGs9HvsTo4/MapvtuE571fw4WqPkK2zdaS/06DO+en6AnXZlnolv5lpe4y3K0RXlayMakUW7zqML619MY+uivWB+XFHjFXC1WXi+cD2NMxXthJAlUBwgxweambdzLXqbsLbTruqHj74ybm5U+frJGhNjL78e9/bjtSko2lV1+Ddpj9jd0wN80vnCfFRFu4go4vH4XT0a0SNRd9prz3PZ1KjvtFs6X4hFFyG186PJfF0A8wwGesRQ5tF9fflkCvKMO7+1mrM1IPZrhiQhxCJtLxhbtB9eAOtHDPSIgR4x0CMGesRAjxhMPjx5AIxHDPSIgR4x0CMGesRAjxjoEQM9YqBHDPSIgR4x0CMGesRAjxjoEQM9YqBHDPSIgR4x0CMGesRAjxjoEQM9YqBHDPSIgR4x0CMGesRAjxjoEQM9YqBHDPSIgR4x0CMGesRAjxjoEQM9YqBHDPSI4R/dCbqojeMuugAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=327x175 at 0x7FF8380F2710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOUAAACvCAAAAAAnYUbAAAAC7UlEQVR4nO2c25aCMAxFUxf//8v1AdSWa9MKbU7OfnFEZ+wmIaQFJ0RxwKv3AB6BljjQEgda4kBLHGiJAy1xoCUOtMSBljjQEgda4kBLHBLLEPoN42ZeIiK4egvuMhYYWuJASxxoiYMPyyl9EkQwb6b4WGI3eZOIBHBHkQneUETk5UHSSY3NQ4lZYVexRJX8nEmiQJ9M5ljCBnFhAo/ijI8a68MSPlkFv+osRB8ZO9fYKCISLkO7Te8/J8PZBLfhtXwWfT2Gz18L300mkj7L2HB6QSh9Le5uHZaf5dVwQ/ZgIoRfFsvzKGasNS0EcxIJRSO1IHPIpB99qMzWIN0SXVNjG/jV5C6iq67geAix4D1HZAd9j9TPYnnPbl5r1WZ8A99YxqvPjqvH9fYjtrF7PppzLIv2bkx6n/KhDlGbNWsF6b4IexuHpa7G/naLPl97oLbMhn0ZyDEkfeBkFu3DUrVWkFBWY3cPy5PfuGutoDaWpiZeaY0tKpjbN2kbtgG69RPmlvvbeNcOtksX8VJ/8iZFNTl72S3fQ3EsNy414+3VDj40ixbp2vH+wfJ89FHC9Zvu5oFYDjBrqe99TJwoF/SW2rWCESi2XMu0njcfpTyWmU5zc/Asiuozr/sop9FjoDkuN0qdOhmyC9cKgJjUh1ZSfUpmpNr5zlBrBbZQW2pCOQwNsbQjyYy9wFAo6y3zu5sGR2uZd+lGJNuOSyuStZbLJQcrKC3TG7fsSNbF0pqk0nI2MydZE0t7krVreLYkfcC1AiAUawXppejCW7fsrRV0vIm3GVXGWpVsuBZ9unkwVNcv95RMJLKTGlv6xjxe5beODkFrLE1IOsnYVksbNZaxxKHOMuz+OC4VdzWF9dPx6+w/MtZEOPHhWgEM8eavCY7yD/Y8xJKWSNASBx+WHb5w3gEfsaQlDrTEgZY40BIHWuJASxxoiQMtcaAlDrTEgZY40BIHWuJASxxoiQMtcaAlDrTEgZY40BIHH5ZvB2x2i0+KrusAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=229x175 at 0x7FF7ADA1FDD0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = continue_image(PRIMUS_TXT_FILES / str(files[38]), seed_length=5, temp=.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
