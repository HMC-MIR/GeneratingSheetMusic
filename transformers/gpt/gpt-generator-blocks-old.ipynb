{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5d999fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast, GPT2Config\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "15da417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 30000\n",
    "MAX_LEN = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d39b6fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZER_SAVEDIR = Path('/home/macosta/ttmp/primus-data/blocks/blocks-v3-tokenizer/')\n",
    "LM_MODEL_SAVEDIR = Path('/home/macosta/ttmp/primus-models/gpt2-lm-blocks-nocols/')\n",
    "PRIMUS_TXT_FILES = Path('/home/ibukey/ttmp/blocks-txt-v3/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d52484a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = GPT2Config(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    n_positions=MAX_LEN,\n",
    "    n_head=12,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b0e85caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel(config=config).from_pretrained(str(LM_MODEL_SAVEDIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "be9c9806",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "file /home/macosta/ttmp/primus-data/blocks/blocks-v3-tokenizer/config.json not found\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2TokenizerFast.from_pretrained(TOKENIZER_SAVEDIR, max_len=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e6d9301a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_image(tokens):\n",
    "    tokens = [t for t in tokens if t not in [\"<s>\", \"</s>\", \"<pad>\"]]\n",
    "    img_array = np.ones((15 * 6 + 5 * 3, ceil(len(tokens) / 6)*15), dtype=np.uint8) * 255\n",
    "    for i in range(5):\n",
    "        img_array[i*18+15:(i*18)+3+15, :] = 0\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token == '<unk>':\n",
    "            token_np = UNK_TOKEN\n",
    "        else:\n",
    "            token_np = np.array([int(x) for x in token]).reshape((15, 15))\n",
    "            token_np = token_np * 255\n",
    "        row = i % 6\n",
    "        column = i // 6\n",
    "        start_row = row * 18\n",
    "        start_column = column * 15\n",
    "        img_array[start_row:start_row+15, start_column:start_column+15] = token_np\n",
    "        img = Image.fromarray(img_array)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fa770ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('<unk>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d349c146",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_TOKEN = ''.join([\"0\" if i % 2 else \"1\" for i in range(225)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dd384350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def continue_image(max_len=512, show=True, show_original=True, temp=1):\n",
    "#     with open(file, 'r') as f:\n",
    "#         data = f.read()\n",
    "#     tokens = data.split()\n",
    "#     index = int(np.random.random()*(len(tokens) - seed_length))\n",
    "#     index = (index // 4) * 4\n",
    "#     seed = tokens[index:index + seed_length]\n",
    "#     if show_original:\n",
    "#         tokens_to_image(seed).show()\n",
    "#         tokens_to_image(tokens[index:index + max_len]).show()\n",
    "#     input_string = f\"{' '.join(seed[-(max_len - 1):])}\"\n",
    "    input_string = '<s>'\n",
    "    inputs = tokenizer.encode(input_string, return_tensors=\"pt\")\n",
    "    output_tokens = model.generate(inputs, \n",
    "                                   min_length=max_len,\n",
    "                                   max_length=max_len, \n",
    "                                   pad_token_id=1,\n",
    "                                   eos_token_id=2,\n",
    "                                   temperature=temp,\n",
    "                                   do_sample=True,\n",
    "                                   bad_words_ids=[[3]])[0]\n",
    "    output_tokens = tokenizer.decode(output_tokens).split()\n",
    "    output_tokens = [UNK_TOKEN if t == '<unk>' else t for t in output_tokens if t not in ['<s>', '</s>', '<pad>']]\n",
    "    img = tokens_to_image(output_tokens)\n",
    "    if show:\n",
    "        img.show()\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "77e6d424",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=1290x105 at 0x7F685CB80610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = continue_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bfc3ca8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_incipits(N, savedir):\n",
    "    savedir.mkdir(exist_ok=True)\n",
    "    for i in range(N):\n",
    "        img = continue_image(show=False)\n",
    "        img.save(savedir / f\"generated_{i}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3e6d6d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_incipits(30, Path('/home/macosta/ttmp/generated-blockwise-v2'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
